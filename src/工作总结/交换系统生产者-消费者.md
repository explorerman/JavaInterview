整体布局图：

![image-20200723164951687](%E4%BA%A4%E6%8D%A2%E7%B3%BB%E7%BB%9F%E7%94%9F%E4%BA%A7%E8%80%85-%E6%B6%88%E8%B4%B9%E8%80%85.assets/image-20200723164951687.png)

product端项目搭建在数据交换平台

consumer端项目搭建在各二级企业的前置机上

中间都是使用Nginx代理

主要逻辑：
product端：

获取OA传输过来的数据后，进行路由处理，根据不同的机构id和路由ip传到各二级企业的前置机

这里使用了concurrenthashmap做了一个简单的缓存

如果发送指定的前置机失败后，会将数据放入一个交换的bean对象进行保存，并新起一个线程，将其放入map中，并使用定时器，每隔5分钟发送一次，如果发送成功，则从map中移除

consumer端：

跟product端相同的操作，接收product传过来的数据，并路由到二级企业端

也使用了定时器进行重发机制。

可能会问的点：

1.定时器是使用的spring的@Scheduled

2.nginx

3.concurrenthashmap（牵扯出1.7，1.8的实现）

4.可以自己引出hashmap

5.spring相关

存在的问题：

1.如果服务挂了，数据就丢失了，缓存失效了，这时候只能重新发送了，或者可以持久化入mysql

2.考虑是否可以使用kafka。